{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZzMPfh8HhFX"
   },
   "source": [
    "# CS 181 Practical, Spring 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APTaS9L1QvAy"
   },
   "outputs": [],
   "source": [
    "# After you've installed a package, you can import it\n",
    "import librosa\n",
    "import pandas as pd\n",
    "\n",
    "#import sklearn functions\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVU_lGLoPwIC"
   },
   "source": [
    "### Set directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directories\n",
    "base_dir = (\"/Users/brentonstefko/Desktop/Harvard/Practical\")\n",
    "\n",
    "## directory to save figures in\n",
    "images_dir = '/Users/brentonstefko/Desktop/Harvard/Practical/images/'\n",
    "\n",
    "## directory to save models in\n",
    "model_dir = '/Users/brentonstefko/Desktop/Harvard/Practical/models/'\n",
    "\n",
    "## directory to save data in\n",
    "data_dir = '/Users/brentonstefko/Desktop/Harvard/Practical/data/'\n",
    "\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vQKC6VJP6Vq"
   },
   "source": [
    "### Load raw amplitude data as a numpy object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EsrrnkJNMUIG"
   },
   "outputs": [],
   "source": [
    "# Load amplitude training and testing data\n",
    "X_amp_train = np.load(data_dir + \"Xtrain_amp.npy\")\n",
    "y_amp_train = np.load(data_dir + \"ytrain_amp.npy\")\n",
    "X_amp_test = np.load(data_dir + \"Xtest_amp.npy\")\n",
    "y_amp_test = np.load(data_dir + \"ytest_amp.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AnugjNjwHdsA",
    "outputId": "148fde5c-ba58-467e-8dca-24ec41742395"
   },
   "outputs": [],
   "source": [
    "X_amp_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0vYPQbnbQGv9",
    "outputId": "f3fb314d-9c9d-46fd-abb5-2a9931b05d8e"
   },
   "outputs": [],
   "source": [
    "X_amp_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOdhs7mQQHcd"
   },
   "source": [
    "### Load mel spectrogram data as a numpy object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3DYzdbAQKXq"
   },
   "outputs": [],
   "source": [
    "# Load mel spectogram training and testing data\n",
    "\n",
    "X_mel_train = np.load(data_dir + \"Xtrain_mel.npy\")\n",
    "y_mel_train = np.load(data_dir + \"ytrain_mel.npy\")\n",
    "X_mel_test = np.load(data_dir + \"Xtest_mel.npy\")\n",
    "y_mel_test = np.load(data_dir + \"ytest_mel.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bztvdo-hQOyH",
    "outputId": "0666dfb1-e804-4239-ffd0-493def4a3d1b"
   },
   "outputs": [],
   "source": [
    "# Flatten X_mel's spectrogram features\n",
    "X_mel_train_flat = X_mel_train.reshape(X_mel_train.shape[0], -1)\n",
    "X_mel_test_flat = X_mel_test.reshape(X_mel_test.shape[0], -1)\n",
    "print(X_mel_train.shape)\n",
    "print(X_mel_train_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btL-QCk9WTxM"
   },
   "source": [
    "### Set up Model/Figure Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drwmUYL0GpZF"
   },
   "outputs": [],
   "source": [
    "## Load Models\n",
    "\n",
    "os.chdir(model_dir)\n",
    "\n",
    "## baseline amplitude model\n",
    "with open(\"logit_amp_base\", \"rb\") as f:\n",
    "  logit_amp_base = pickle.load(f)\n",
    "\n",
    "## baseline logit model\n",
    "with open(\"logit_mel_base\", 'rb') as f:\n",
    "  logit_mel_base = pickle.load(f)\n",
    "\n",
    "# Logit Search\n",
    "with open(\"logit_mel_search\", \"rb\") as f:\n",
    "  logit_mel_search = pickle.load(f)\n",
    "\n",
    "# Logit Opt\n",
    "with open(\"logit_mel_opt\", \"rb\") as f:\n",
    "  logit_mel_opt = pickle.load(f)\n",
    "\n",
    "# KNN base\n",
    "with open(\"knn_mel_base\", \"rb\") as f:\n",
    "  knn_mel_base = pickle.load(f)\n",
    "\n",
    "# KNN search\n",
    "with open(\"knn_mel_search\", \"rb\") as f:\n",
    "  knn_mel_search = pickle.load(f)\n",
    "\n",
    "# KNN opt\n",
    "with open(\"knn_mel_opt\", \"rb\") as f:\n",
    "  knn_mel_opt = pickle.load(f)\n",
    "\n",
    "\n",
    "# Models AMP STD\n",
    "with open(\"models_amp_std_list\", \"rb\") as f:\n",
    "  models_amp_std_list = pickle.load(f)\n",
    "\n",
    "\n",
    "# Models MEL STD\n",
    "with open(\"models_mel_std_list\", \"rb\") as f:\n",
    "  models_mel_std_list = pickle.load(f)\n",
    "\n",
    "\n",
    "# KNN STD \n",
    "with open(\"knn_mel_std\", \"rb\") as f:\n",
    "  knn_mel_std = pickle.load(f)\n",
    "\n",
    "# Models KNN STD Search\n",
    "with open(\"knn_mel_std_search\", \"rb\") as f:\n",
    "  knn_mel_std_search = pickle.load(f)\n",
    "\n",
    "# Optimal KNN Std model\n",
    "with open(\"knn_mel_std_opt\", \"rb\") as f:\n",
    "  knn_mel_std_opt = pickle.load(f)\n",
    "\n",
    "\n",
    "##### Load in Data that takes time to run\n",
    "with open(\"data_pca\", \"rb\") as f:\n",
    "  data_pca = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzqsItcde0kv"
   },
   "source": [
    "# Beginning of Project\n",
    "### CS 181 Practical, Spring 2021\n",
    "### Author: Brenton Stefko\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yviSYgRfFNR"
   },
   "source": [
    "## Overview\n",
    "\n",
    "\n",
    "1.   Understand the shape of the data\n",
    "1.   Data Cleaning\n",
    "1. Data Exploration\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5nb-6lLRldmY"
   },
   "source": [
    "### Amplitude Data \n",
    "* Is a 5553 x 44100 (N x D) dataset\n",
    "* Each observation corresponds to a sound recording of a given category\n",
    "* The 2nd dimension corresponds to the each timestep of the recording\n",
    "* The data are the sampled signal amplitudes at each timestep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VkctWHuceuZF",
    "outputId": "a5e17f6e-a416-469e-faf5-c71aefafddd1"
   },
   "outputs": [],
   "source": [
    "print(X_amp_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9M6m9erVnS7V"
   },
   "source": [
    "### Mel Spectogram Data\n",
    "* Spectogram is a representation of the frequencies of a signal as it varies over time\n",
    "* For each observation, the time dimension is partitioned into 87 sub sequences\n",
    "* The Mel Spectogram data represents the presence of 128 frequencies in the 87 sub-sequences\n",
    "* Flattening the dataset results in a 5553 x 11136 dataset with each column representing a given frequency - sub sequence combination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V7FWW9l9mRQ9",
    "outputId": "db410685-7afd-4803-ae44-c5b7f4d4e083"
   },
   "outputs": [],
   "source": [
    "# print dimension of X_mel_train\n",
    "print(X_mel_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mE4CgJ1Lop-5",
    "outputId": "4531299c-b845-4db2-a7d7-0467740ebd16"
   },
   "outputs": [],
   "source": [
    "# print dimension of X_mel_train_flat\n",
    "print(X_mel_train_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEougCmMplmy"
   },
   "source": [
    "### Descriptive Analysis\n",
    "* Want to understand the distribution of the amplitude and frequencies \n",
    "> In particular: Do these distributions differ by category? Plot Histograms, Boxplots for each category\n",
    "* Are there any outliers in the data that might be worth trimming?\n",
    "* Are there missing values present in the data, and how should we treat these?\n",
    "> E.g., we could replace a missing with the column mean of the affected category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-aGVeMUIahRp"
   },
   "source": [
    "## Plots:\n",
    "1. Time Series Plot plotting the average for each category at any given point in time +- 2 SD\n",
    "> This should give a good idea of the data\n",
    "<br>\n",
    "> It will be necessary to reduce data to a certain extent: Split the time dimension into intervals and then get the average for each interval/category combination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dVBgNehhsDnV",
    "outputId": "d71a0776-8473-47cc-fac8-cd8c5b9bb868"
   },
   "outputs": [],
   "source": [
    "# Get frequencies of different categories in amplitude data\n",
    "unique_amp, counts_amp = np.unique(y_amp_train, return_counts = True)\n",
    "print(np.asarray((unique_amp, counts_amp)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cek3ekPWs8u0",
    "outputId": "45e12e18-431f-4fca-cb4a-94e6db725a14"
   },
   "outputs": [],
   "source": [
    "# Get frequencies of different categories in spectogram data\n",
    "unique_mel, counts_mel = np.unique(y_mel_train, return_counts = True)\n",
    "print(np.asarray((unique_mel, counts_mel)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ooNkHECFrEW_"
   },
   "outputs": [],
   "source": [
    "## Get a dictionary for each category seperately\n",
    "\n",
    "cat_data = {}\n",
    "cat_data_mel = {}\n",
    "\n",
    "def get_cat_data(name, index):\n",
    "  X_amp_train_cat = X_amp_train[y_amp_train == index, :]\n",
    "  return(X_amp_train_cat)\n",
    "\n",
    "def get_cat_data_mel(name, index):\n",
    "  X_mel_train_cat = X_mel_train_flat[y_mel_train == index, :]\n",
    "  return(X_mel_train_cat)\n",
    "\n",
    "cat_dict = {0:\"AC\", 1:\"Car Horn\", 2:\"Child\", 3:\"Dog\", 4:\"Drill\", 5:\"Engine\", 6:\"Gun\", 7:\"Jackhammer\", 8:\"Siren\", 9:\"Music\"}\n",
    "\n",
    "for index, name  in cat_dict.items():\n",
    "  X_data = get_cat_data(name, index)\n",
    "  X_data_mel = get_cat_data_mel(name, index)\n",
    "  cat_data['{}'.format(name)] = X_data\n",
    "  cat_data_mel['{}'.format(name)] = X_data_mel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kk26yCzFnN3H"
   },
   "outputs": [],
   "source": [
    "# Reduce each of the arrays in the dictionary to 441 time periods\n",
    "cat_data_means = {}\n",
    "cat_data_means_mel = {}\n",
    "cat_data_std = {}\n",
    "names = [\"AC\", \"Car Horn\", \"Child\", \"Dog\", \"Drill\", \"Engine\", \"Gun\", \"Jackhammer\", \"Siren\", \"Music\"]\n",
    "\n",
    "\n",
    "def get_reduced_data(arr, step):\n",
    "\n",
    "  # Initiate variables\n",
    "  X_init = arr[:, 0:step]\n",
    "  X_mean = np.mean(X_init).reshape(-1, 1)\n",
    "  X_std = np.std(X_init).reshape(-1, 1)\n",
    "\n",
    "  for j in range(step, arr.shape[1], step):\n",
    "    X_next = arr[:, j:(j+step)]\n",
    "    mean_next = np.mean(X_next).reshape(-1, 1)\n",
    "    std_next = np.std(X_next).reshape(-1, 1)\n",
    "\n",
    "    # append the values to the final data\n",
    "    X_mean = np.concatenate((X_mean, mean_next), axis = 0)\n",
    "    X_std = np.concatenate((X_std, std_next), axis = 0)\n",
    "\n",
    "  return(X_mean, X_std)\n",
    "\n",
    "for name in names:\n",
    "  cat_mean, cat_std = get_reduced_data(cat_data[name], 50)\n",
    "  cat_mean_mel, _ = get_reduced_data(cat_data_mel[name], 50)\n",
    "  cat_data_means['{}'.format(name)] = cat_mean\n",
    "  cat_data_std['{}'.format(name)] = cat_std\n",
    "  cat_data_means_mel['{}'.format(name)] = cat_mean_mel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mel Spectogram Data\n",
    "print(X_mel_train_flat.mean(), X_mel_train_flat.std())\n",
    "mel_train_hist, _ = get_reduced_data(X_mel_train_flat, 50)\n",
    "\n",
    "# plot histogram of mel spectogram data\n",
    "plt.figure(figsize=(3, 3), dpi=200)\n",
    "plt.hist(mel_train_hist)\n",
    "plt.title('Mel Spectogram')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{images_dir}/mel_spectogram_hist.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Amplitude Data\n",
    "print(X_amp_train.mean(), X_amp_train.std())\n",
    "amp_hist, _ = get_reduced_data(X_amp_train, 50)\n",
    "\n",
    "# plot histogram of mel spectogram data\n",
    "plt.figure(figsize=(3, 3), dpi=200)\n",
    "plt.hist(amp_hist)\n",
    "plt.title('Amplitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{images_dir}/amplitude_overall_hist.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "55deAc4DrLYp",
    "outputId": "1120a79f-285b-4719-b613-4ed577798a85"
   },
   "outputs": [],
   "source": [
    "## Get chart with histograms for each label\n",
    "# first, we tell matplotlib to start a new figure\n",
    "plt.figure(figsize=(12, 20), dpi=200)\n",
    "\n",
    "i = 0\n",
    "\n",
    "# loop through categories\n",
    "for name in names:\n",
    "  \n",
    "  # iterate on chart index (starts at 1 for matplotlib)\n",
    "  i = i + 1\n",
    "\n",
    "  # add subplot to figure \n",
    "  # this tells matplotlib to add a subplot to our figure (5 rows, 2 cols)\n",
    "  plt.subplot(5, 2, i)\n",
    "  \n",
    "  # plot histogram\n",
    "  plt.hist(cat_data_means[name])\n",
    "\n",
    "  # Set the range of x-axis\n",
    "  plt.xlim(-0.06, 0.06)\n",
    "  \n",
    "  # add in the label + title\n",
    "  plt.title(name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{images_dir}/histograms.pdf\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get chart with histograms for each label\n",
    "# first, we tell matplotlib to start a new figure\n",
    "plt.figure(figsize=(12, 20), dpi=200)\n",
    "\n",
    "i = 0\n",
    "\n",
    "# loop through categories\n",
    "for name in names:\n",
    "  \n",
    "  # iterate on chart index (starts at 1 for matplotlib)\n",
    "  i = i + 1\n",
    "\n",
    "  # add subplot to figure \n",
    "  # this tells matplotlib to add a subplot to our figure (5 rows, 2 cols)\n",
    "  plt.subplot(5, 2, i)\n",
    "  \n",
    "  # plot histogram\n",
    "  plt.hist(cat_data_means_mel[name])\n",
    "\n",
    "  # Set the range of x-axis\n",
    "  #plt.xlim(-0.06, 0.06)\n",
    "  \n",
    "  # add in the label + title\n",
    "  plt.title(name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{images_dir}/histograms_mel_by_cat.pdf\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Egj81haCt6ee",
    "outputId": "ec6db357-0fa1-4bdc-ba74-d3a1510efef9"
   },
   "outputs": [],
   "source": [
    "# Generate a line chart for each category\n",
    "# first, tell matplotlib to start a new figure\n",
    "plt.figure(figsize=(12, 20), dpi=200)\n",
    "\n",
    "i = 0\n",
    "\n",
    "# the odd thing is that in this type of subplot, matplotlib starts counting from 1, as opposed to 0.\n",
    "for name in names:\n",
    "  \n",
    "   # iterate on chart index (starts at 1 for matplotlib)\n",
    "  i = i + 1\n",
    "\n",
    "  # add subplot to figure \n",
    "  # this tells matplotlib to add a subplot to our figure (5 rows, 2 cols)\n",
    "  plt.subplot(5, 2, i)\n",
    "  \n",
    "  # line plot\n",
    "  plt.plot(cat_data_means[name], color= \"blue\", label =\"mean\")\n",
    "\n",
    "  #get y limit\n",
    "  plt.ylim(-0.06, 0.06)\n",
    "  \n",
    "  # add in the label + title\n",
    "  plt.title(name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{images_dir}/time-series.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3K1JOyJpu_lG",
    "outputId": "75bb981a-65df-429f-ad50-fd2d97d2737f"
   },
   "outputs": [],
   "source": [
    "## Generate area plots with 95% Confidence interval\n",
    "\n",
    "# need an array for the x-axis\n",
    "x_axis = np.arange(0, cat_data_means['AC'].shape[0])\n",
    "\n",
    "# function to get the upper and lower bounds for the area plot\n",
    "def get_bounds(name):\n",
    "  up = cat_data_means[name] + 2*cat_data_std[name]\n",
    "  low = cat_data_means[name] - 2*cat_data_std[name]\n",
    "  mean = cat_data_means[name]\n",
    "  up = up.ravel(\"F\")\n",
    "  low = low.ravel(\"F\")\n",
    "  mean = mean.ravel(\"F\")\n",
    "  return(up, low, mean)\n",
    "\n",
    "\n",
    "# first, tell matplotlib to start a new figure\n",
    "plt.figure(figsize=(12, 20), dpi=200)\n",
    "\n",
    "i = 0\n",
    "\n",
    "# the odd thing is that in this type of subplot, matplotlib starts counting from 1, as opposed to 0.\n",
    "for name in names:\n",
    "\n",
    "  # iterate on chart index (starts at 1 for matplotlib)\n",
    "  i = i + 1\n",
    "\n",
    "  # get upper and lower bounds\n",
    "  up, low, mean = get_bounds(name)\n",
    "\n",
    "  # add subplot to figure \n",
    "  # this tells matplotlib to add a subplot to our figure (5 rows, 2 cols)\n",
    "  plt.subplot(5, 2, i)\n",
    "  \n",
    "  # ylim\n",
    "  plt.ylim(-0.65, 0.65)\n",
    "  \n",
    "  # Plot lines\n",
    "  plt.plot(x_axis, mean, color = \"blue\", label = \"Mean\")\n",
    "\n",
    "  # Fill area between upper and lower\n",
    "  plt.fill_between(\n",
    "      x_axis, up, low, interpolate=True, color=\"blue\", alpha=0.25, label=\"95% Confidence band\"\n",
    "  )\n",
    "\n",
    "    \n",
    "  # add in the label + title\n",
    "  plt.title(name)\n",
    "  plt.legend();\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{images_dir}/CI.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Mel Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_mel_train[0])\n",
    "fig, ax = plt.subplots()\n",
    "S_dB = librosa.power_to_db(X_mel_train[0], ref=np.max)\n",
    "img = librosa.display.specshow(S_dB, x_axis='time',y_axis='mel')\n",
    "fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "ax.set(title='Mel-frequency spectrogram, ' + names[y_mel_train[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "S_dB = librosa.power_to_db(X_mel_train[1], ref=np.max)\n",
    "img = librosa.display.specshow(S_dB, x_axis='time', y_axis='mel')\n",
    "fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "ax.set(title='Mel-frequency spectrogram, ' + names[y_mel_train[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "S_dB = librosa.power_to_db(X_mel_train[6], ref=np.max)\n",
    "img = librosa.display.specshow(S_dB, x_axis='time', y_axis='mel')\n",
    "fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "ax.set(title='Mel-frequency spectrogram, ' + names[y_mel_train[6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms of overall distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlIYsekMItHe"
   },
   "source": [
    "# Logistic Regression Models\n",
    "\n",
    "### Baseline Models\n",
    "1. Train a logistic regression model (without regularization) on the raw Amplitude data\n",
    "1. Train a logistic regression model (without regularizartion) on the raw Mel Spectogram data\n",
    "\n",
    "### Include Feature Engineering on these Datasets\n",
    "1. Standardize the individual features ()\n",
    "1. Transform using principal component analysis\n",
    "1. Maybe: Standardize Data\n",
    "\n",
    "### Use GridsearchCV to tune hyperperameters (only one feature representation)\n",
    "1. L1, L2 Regularization\n",
    "1. Different regularization strengths\n",
    "1. Perform this on the raw data, the quadratic data, and PCA data \n",
    "\n",
    "### For each of the models:\n",
    "* Compute Training/Testing Accuracy\n",
    "* Compute AUC Score\n",
    "* Plot ROC Curve for the initial logistic regressions and for the best-performing model\n",
    "* After finding the model that performs best among the ones you tried, consider reweighting the data to boost performance among the classes that did not perform well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aL6H7bbKK5z8"
   },
   "source": [
    "### Prerequisite Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uw4ejU2oFI-T"
   },
   "outputs": [],
   "source": [
    "## Define a function to get ROC Data and Curve\n",
    "\n",
    "# Inputs are X_test, y_test, model\n",
    "\n",
    "def get_ROC(X_test, y_test, model, figname):\n",
    "\n",
    "  ## Get Data for ROC curve (matrix of probabilities, one-hot encoded y-test)\n",
    "  probs = model.predict_proba(X_test)\n",
    "  label_binarizer = LabelBinarizer().fit(y_test)\n",
    "  y_onehot_test = label_binarizer.transform(y_test)\n",
    "\n",
    "  ## Calculate ROC Score\n",
    "  micro_roc_auc_ovr = roc_auc_score(\n",
    "      y_test,\n",
    "      probs,\n",
    "      multi_class=\"ovr\",\n",
    "      average=\"micro\",\n",
    "  )\n",
    "\n",
    "  print(f\"Micro-averaged One-vs-Rest ROC AUC score:\\n{micro_roc_auc_ovr:.2f}\")\n",
    "\n",
    "  # dictionary defining labels and colors\n",
    "  label_dict = {0:(\"AC\",\"royalblue\"), 1:(\"Car Horn\",\"darkorange\"), 2:(\"Child\",\"darkgrey\"), 3:(\"Dog\",\"magenta\"), \n",
    "              4:(\"Drill\",\"gold\"), 5:(\"Engine\",\"lawngreen\"), 6:(\"Gun\", \"teal\"), 7:(\"Jackhammer\", \"dimgrey\"), 8:(\"Siren\",\"firebrick\"), 9:(\"Music\", \"pink\")}\n",
    "\n",
    "  fig, ax = plt.subplots(figsize=(8, 8), dpi = 100)\n",
    "\n",
    "\n",
    "  for class_id, specs in label_dict.items():\n",
    "    name = specs[0]\n",
    "    color = specs[1]\n",
    "    RocCurveDisplay.from_predictions(\n",
    "      y_onehot_test[:, class_id],\n",
    "      probs[:, class_id],\n",
    "      name=f\"{name}\",\n",
    "      color=color,\n",
    "      ax = ax,\n",
    "  )\n",
    "    \n",
    "  RocCurveDisplay.from_predictions(\n",
    "      y_onehot_test.ravel(),\n",
    "      probs.ravel(),\n",
    "      name=\"Average OvR\",\n",
    "      color=\"darkviolet\",\n",
    "      ax = ax,\n",
    "  )\n",
    "\n",
    "  plt.plot([0, 1], [0, 1], \"k--\", label=\"Chance Level (AUC = 0.5)\")\n",
    "  plt.axis(\"square\")\n",
    "  plt.xlabel(\"False Positive Rate\")\n",
    "  plt.ylabel(\"True Positive Rate\")\n",
    "  plt.title(\"One-vs-Rest ROC curves\")\n",
    "  plt.legend()\n",
    "  plt.savefig(f\"{images_dir}/{figname}.pdf\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LTcovDCL5KH3"
   },
   "outputs": [],
   "source": [
    "\n",
    "cat_dict = {0:\"AC\", 1:\"Car Horn\", 2:\"Child\", 3:\"Dog\", 4:\"Drill\", 5:\"Engine\", 6:\"Gun\", 7:\"Jackhammer\", 8:\"Siren\", 9:\"Music\"}\n",
    "\n",
    "def per_class_accuracy(X_train, y_train, X_test, y_test, model):\n",
    "\n",
    "  train_preds = model.predict(X_train)\n",
    "  test_preds = model.predict(X_test)\n",
    "\n",
    "  train_accuracies = {}\n",
    "  test_accuracies = {}\n",
    "\n",
    "  for num, label in cat_dict.items():\n",
    "    class_train_preds = train_preds[y_train == num]\n",
    "    class_test_preds = test_preds[y_test == num]\n",
    "\n",
    "    corr_train_preds = class_train_preds[class_train_preds == num].shape[0]\n",
    "    corr_test_preds = class_test_preds[class_test_preds == num].shape[0]\n",
    "\n",
    "    train_accuracies[label] = corr_train_preds/class_train_preds.shape[0]\n",
    "    test_accuracies[label] = corr_test_preds/class_test_preds.shape[0]\n",
    "  \n",
    "  # print result\n",
    "  for label, _ in train_accuracies.items():\n",
    "    print(f\"{label}; Train Accuracy: {train_accuracies[label]:.2f}; Test Accuracy: {test_accuracies[label]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_scores(X_train, y_train, X_test, y_test, model):\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    print(f\"Train Accuracy:\\n{train_score:.2f}\")\n",
    "    print(f\"Test Accuracy:\\n{test_score:.2f}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(X_train, y_train, X_test, y_test, model, ROC_figname):\n",
    "\n",
    "    print(\"Overall Evaluation Metrics:\\n\")\n",
    "    eval_scores(X_train, y_train, X_test, y_test, model)\n",
    "    print(\"\\nPer-Class Evaluation Metrics:\\n\")\n",
    "    per_class_accuracy(X_train, y_train, X_test, y_test, model)\n",
    "    get_ROC(X_test, y_test, model, ROC_figname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hm0IRUuC-piY"
   },
   "source": [
    "### Train a Baseline Logistic Regression Model - Amplitude Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ojl0aIwYR9Ex"
   },
   "outputs": [],
   "source": [
    "# Define a baseline logistic regression\n",
    "logit_base = LogisticRegression(penalty = None, max_iter = 1000, \n",
    "                                    fit_intercept = True, multi_class = 'multinomial', solver = 'lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "jGzlVcdgAluN",
    "outputId": "06ddbe0a-da84-4392-f00d-1ced54d78442"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Baseline logistic regression using amplitude data\n",
    "logit_amp_base = logit_base.fit(X_amp_train, y_amp_train)\n",
    "\n",
    "# Save Model\n",
    "with open (\"logit_amp_base\", \"wb\") as f:\n",
    "  pickle.dump(logit_amp_base, f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get classification results\n",
    "get_results(X_amp_train, y_amp_train, X_amp_test, y_amp_test, logit_amp_base, 'ROC_baseline_amp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zh3fdJeTHl-e"
   },
   "source": [
    "### Train a Baseline Logistic Regression Model - Mel Spectogram Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "cnmCwVUDHerk",
    "outputId": "bd17628b-917a-4a2e-b5fa-d9d418754775"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Baseline logistic regression using mel spectogram data\n",
    "logit_mel_base = logit_base.fit(X_mel_train_flat, y_mel_train)\n",
    "\n",
    "# Save Model\n",
    "with open (\"logit_mel_base\", \"wb\") as f:\n",
    "  pickle.dump(logit_mel_base, f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results\n",
    "get_results(X_mel_train_flat, y_mel_train, X_mel_test_flat, y_mel_test, logit_mel_base, 'ROC_baseline_mel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OS_JUnJ8FhA8"
   },
   "source": [
    "### Try different standardizations of Amplitude and Mel Spectogram Data\n",
    "> Get Mel Spectogram Data into format of a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Functions to Scale Data\n",
    "# Always have to scale train and test data in the same way\n",
    "\n",
    "def std_scaler(X_train, X_test):\n",
    "  \n",
    "  ## Scale data - Standard Scaler\n",
    "  scaler = StandardScaler()\n",
    "  scaler = scaler.fit(X_train)\n",
    "  X_train_std = scaler.transform(X_train)\n",
    "  X_test_std = scaler.transform(X_test)\n",
    "  return(X_train_std, X_test_std)\n",
    "\n",
    "\n",
    "def minmax_scaler(X_train, X_test):\n",
    "\n",
    "  train_min = X_train.min()\n",
    "  train_max = X_train.max()\n",
    "  scaler = MinMaxScaler(feature_range=(train_min, train_max))\n",
    "  scaler = scaler.fit(X_train)\n",
    "  X_train_scaled = scaler.transform(X_train)\n",
    "  X_test_scaled = scaler.transform(X_test)\n",
    "  return(X_train_scaled, X_test_scaled)\n",
    "\n",
    "def pt_scaler(X_train, X_test):\n",
    "  pt = PowerTransformer()\n",
    "  pt = pt.fit(X_train)\n",
    "  X_train_log = pt.transform(X_train)\n",
    "  X_test_log = pt.transform(X_test)\n",
    "  return(X_train_log, X_test_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZPpTeGO0F2Ma"
   },
   "outputs": [],
   "source": [
    "# Get Data into a dictionary\n",
    "data_dict = {'amp':(X_amp_train, y_amp_train, X_amp_test, y_amp_test), 'mel':(X_mel_train_flat, y_mel_train, X_mel_test_flat, y_mel_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xTKtQHPHHda"
   },
   "outputs": [],
   "source": [
    "## Get Scaled Data\n",
    "data_std = {}\n",
    "\n",
    "for label, vars in data_dict.items():\n",
    "  if label == 'amp':\n",
    "    X_train_std, X_test_std = std_scaler(vars[0], vars[2])\n",
    "    data_std['std {}'.format(label)] = (X_train_std, vars[1], X_test_std, vars[3])\n",
    "  elif label == 'mel':\n",
    "    X_train_log, X_test_log = pt_scaler(vars[0], vars[2])\n",
    "    data_std['log {}'.format(label)] = (X_train_log, vars[1], X_test_log, vars[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_KEu369Ep4El",
    "outputId": "0c97e73f-0d7f-45ed-d6b5-5e5855644066"
   },
   "outputs": [],
   "source": [
    "std_list = ['std amp', 'log mel']\n",
    "\n",
    "for j in std_list:\n",
    "  print(data_std[j][0].shape, data_std[j][1].shape, data_std[j][2].shape, data_std[j][3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for mean zero and unit variance for PCA\n",
    "for j in std_list:\n",
    "    print(data_std[j][0].mean(), data_std[j][0].std(), data_std[j][2].mean(), data_std[j][2].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get histogram of transformed Mel data\n",
    "X_mel_log_hist , _ = get_reduced_data(data_std['log mel'][0], 50)\n",
    "\n",
    "# plot histogram of mel spectogram data\n",
    "plt.figure(figsize=(3, 3), dpi=200)\n",
    "plt.hist(X_mel_log_hist)\n",
    "plt.title('Mel Spectogram Transformed')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{images_dir}/mel_transformed_hist.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZKGQWTl8NiMI"
   },
   "outputs": [],
   "source": [
    "# Define list of model names for each feature\n",
    "amp_std = ['std amp']\n",
    "mel_std = ['log mel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "41xM18_HQ1-m",
    "outputId": "ef54a93a-db17-46d2-8ae9-dc9e3564b527"
   },
   "outputs": [],
   "source": [
    "# Get Amp List of standardized models\n",
    "'''\n",
    "models_amp_std_list = {}\n",
    "\n",
    "\n",
    "for label in amp_std:\n",
    "  print(label)\n",
    "  print(data_std[label][0].shape)\n",
    "  print(data_std[label][1].shape)\n",
    "  models_amp_std_list['{}'.format(label)] = logit_base.fit(data_std[label][0], data_std[label][1])\n",
    "\n",
    "# Save model list\n",
    "with open (\"models_amp_std_list\", \"wb\") as f:\n",
    "  pickle.dump(models_amp_std_list, f)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "3G3MGK8l4iet",
    "outputId": "4cc7697c-8a11-4d10-cd0d-88db92069fa6"
   },
   "outputs": [],
   "source": [
    "# Get Mel List of standardized models\n",
    "\n",
    "'''\n",
    "models_mel_std_list = {}\n",
    "\n",
    "for label in mel_std:\n",
    "  print(label)\n",
    "  print(data_std[label][0].shape)\n",
    "  print(data_std[label][1].shape)\n",
    "  models_mel_std_list['{}'.format(label)] = logit_base.fit(data_std[label][0], data_std[label][1])\n",
    "\n",
    "# Save model list\n",
    "with open (\"models_mel_std_list\", \"wb\") as f:\n",
    "  pickle.dump(models_mel_std_list, f)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OOntNyfTUupd",
    "outputId": "c78d5d80-9ebf-4efc-a766-7103435e4eb4"
   },
   "outputs": [],
   "source": [
    "## Calculate Evaluation Metrics\n",
    "\n",
    "for item in amp_std:\n",
    "  print(item)\n",
    "  eval_scores(data_std[item][0], data_std[item][1], data_std[item][2], data_std[item][3], models_amp_std_list[item])\n",
    "\n",
    "for item in mel_std:\n",
    "  print(item)\n",
    "  eval_scores(data_std[item][0], data_std[item][1], data_std[item][2], data_std[item][3], models_mel_std_list[item])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 934
    },
    "id": "iq_dz0icBI2g",
    "outputId": "0f5f2487-9011-47f2-c910-730a01abe3cf"
   },
   "outputs": [],
   "source": [
    "get_results(data_std['log mel'][0], data_std['log mel'][1], data_std['log mel'][2], data_std['log mel'][3], models_mel_std_list['log mel'], 'ROC_mel_spectogram_std')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8UKy3A9ybHM"
   },
   "source": [
    "## Principal Component Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qeo70qWBA_uX",
    "outputId": "5ac3522b-e1f6-4239-b239-d07ed592c547"
   },
   "outputs": [],
   "source": [
    "for item, _ in data_std.items():\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44NJ9MFy6YtH"
   },
   "outputs": [],
   "source": [
    "# Define function to return PCA data\n",
    "\n",
    "def get_pca_data(X_train, X_test, pca_n):\n",
    "  pca_fit = PCA(n_components = pca_n)\n",
    "  pca_fit = pca_fit.fit(X_train)\n",
    "  X_train_pca = pca_fit.transform(X_train)\n",
    "  X_test_pca = pca_fit.transform(X_test)\n",
    "  return(X_train_pca, X_test_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "A1GefbHNDZ4g",
    "outputId": "0f0d7de0-43cd-41b6-d3e6-428b50b44503"
   },
   "outputs": [],
   "source": [
    "# Get PCA data\n",
    "\n",
    "'''\n",
    "# use 95% of the variation in the X data\n",
    "pca_n = 0.95\n",
    "data_pca = {}\n",
    "\n",
    "for label, vars in data_std.items():\n",
    "  X_train_pca, X_test_pca = get_pca_data(data_std[label][0], data_std[label][2], pca_n)\n",
    "  data_pca[label] = (X_train_pca, vars[1], X_test_pca, vars[3])\n",
    "\n",
    "# save the PCA data (takes some time to run)\n",
    "with open (model_dir + \"data_pca\", \"wb\") as f:\n",
    "  pickle.dump(data_pca, f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hgbSLzz76Li"
   },
   "outputs": [],
   "source": [
    "# Define function to return PCA Results\n",
    "\n",
    "def get_pca_results(label, X_train_pca, y_train, X_test_pca, y_test, X_train_std, pca_n):\n",
    "\n",
    "  # Print Output\n",
    "  print(f\"Data: {label}\")\n",
    "  print(f\"No. Components:\\n{X_train_pca.shape[1]:.0f}\")\n",
    "\n",
    "  # Initialize figure\n",
    "  x_inter = X_train_pca.shape[1] # X intercept\n",
    "  no_row = X_train_std.shape[0] + 1\n",
    "\n",
    "  pca = PCA().fit(X_train_std)\n",
    "  xi = np.arange(1, no_row, step=1)\n",
    "  y = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "  ## Plot Figure\n",
    "  plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "  fig, ax = plt.subplots()\n",
    "\n",
    "  plt.ylim(0.0,1.1)\n",
    "  plt.plot(xi, y, linestyle='--', color='b')\n",
    "\n",
    "  plt.xlabel('Number of Components')\n",
    "  plt.xticks(np.arange(0, no_row, step=1000))  #change from 0-based array index to 1-based human-readable label\n",
    "  plt.ylabel('Cumulative variance (%)')\n",
    "  plt.title(f'The number of components needed to explain variance - {label}')\n",
    "\n",
    "  plt.axhline(y=pca_n, color='r', linestyle='-')\n",
    "  plt.axvline(x = x_inter, color = 'black', linestyle = '-' )\n",
    "  plt.text(0.5, 0.85, '95% cut-off threshold', color = 'red', fontsize=16)\n",
    "\n",
    "  ax.grid(axis='x')\n",
    "  plt.savefig(f\"{images_dir}/pca_analysis_{label}.pdf\")\n",
    "  plt.show()\n",
    "\n",
    "  ## Train model\n",
    "  logit_pca = logit_base.fit(X_train_pca, y_train)\n",
    "\n",
    "  # Calculate Evaluation Metrics\n",
    "  train_score = logit_pca.score(X_train_pca, y_train)\n",
    "  test_score = logit_pca.score(X_test_pca, y_test)\n",
    "  print(f\"Train Accuracy:\\n{train_score:.2f}\")\n",
    "  print(f\"Test Accuracy:\\n{test_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "JnbDpQOe-99-",
    "outputId": "d5dd1808-b178-49d4-d003-4be9f5a575fb"
   },
   "outputs": [],
   "source": [
    "\n",
    "for label, _ in data_pca.items():\n",
    "  print(label)\n",
    "  get_pca_results(label, data_pca[label][0], data_pca[label][1], data_pca[label][2], data_pca[label][3], data_std[label][0], pca_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nlbw6YsjD8QY"
   },
   "source": [
    "## Multinomial Logit - Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQnELCzaNxcZ"
   },
   "source": [
    "### Mel Spectogram Data - PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_pca['log mel'][0].shape)\n",
    "print(data_pca['log mel'][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F63PgFJwNy_6"
   },
   "outputs": [],
   "source": [
    "# Use GridSearchCV to find optimal penalty and number of learning steps, according to 5-fold cv\n",
    "params = {'C':[1, 0.9, 0.75, 0.5, 0.25, 0.1, 0.01, 0.001, 0.0005, 0.0001]}\n",
    "logit_search = LogisticRegression(fit_intercept=True, penalty = 'l2', multi_class = 'multinomial', max_iter = 3000, solver = 'lbfgs')\n",
    "logit_search = GridSearchCV(logit_search, params, cv = 5,scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "cIIaeabKhnut",
    "outputId": "1003bde6-aee1-47c1-a21a-c5b5f9c34f7d"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Fit model \n",
    "logit_mel_search = logit_search.fit(data_pca['log mel'][0], data_pca['log mel'][1])\n",
    "\n",
    "# Save model\n",
    "with open (model_dir + \"logit_mel_search\", \"wb\") as f:\n",
    "  pickle.dump(logit_mel_search, f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "E9f8Ddcn8fuD",
    "outputId": "7613978c-a5eb-4d1f-ef24-6dd54fbb8a65"
   },
   "outputs": [],
   "source": [
    "logit_mel_search_results = pd.DataFrame(logit_mel_search.cv_results_).sort_values(by=['rank_test_score'])\n",
    "logit_mel_search_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LNbxg_n7O6Sr",
    "outputId": "bcf381a6-88af-4ef2-de55-cc677a7db918"
   },
   "outputs": [],
   "source": [
    "# Get the best parameters according to GridSearch\n",
    "print(logit_mel_search.best_params_)\n",
    "logit_mel_best_params = logit_mel_search.best_params_\n",
    "logit_mel_opt_ins = LogisticRegression(penalty = 'l2', fit_intercept=True, multi_class = 'multinomial',\n",
    "                                   C = logit_mel_best_params['C'], max_iter = 3000, solver = 'lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "7i-5LILiYBjt",
    "outputId": "a3fac286-3d69-457f-c74a-8661f5308926"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Train Model \n",
    "logit_mel_opt = logit_mel_opt_ins.fit(data_pca['log mel'][0], data_pca['log mel'][1])\n",
    "\n",
    "# Save model\n",
    "with open (model_dir + \"logit_mel_opt\", \"wb\") as f:\n",
    "  pickle.dump(logit_mel_opt, f)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get results for optimal model\n",
    "get_results(data_pca['log mel'][0], data_pca['log mel'][1], data_pca['log mel'][2], data_pca['log mel'][3], logit_mel_opt, 'ROC_logit_mel_opt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jX-9MUbIkz0e"
   },
   "source": [
    "## Training a KNN Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKBYBC98QHQZ"
   },
   "source": [
    "### Raw Mel Spectogram Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kyTHDQDBk5x8"
   },
   "outputs": [],
   "source": [
    "knn_base = KNeighborsClassifier(n_neighbors = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "YkFtIu3UqN27",
    "outputId": "e63f3a6f-5e32-456d-d5a1-3b78292a50c9"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Calculate base KNN model\n",
    "knn_mel_base = knn_base.fit(X_mel_train_flat, y_mel_train)\n",
    "\n",
    "# Save model\n",
    "with open (model_dir + \"knn_mel_base\", \"wb\") as f:\n",
    "  pickle.dump(knn_mel_base, f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results(X_mel_train_flat, y_mel_train, X_mel_test_flat, y_mel_test, knn_mel_base, 'ROC_knn_base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDEjioJQQNM2"
   },
   "source": [
    "### Powertransformed Spectogram Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "T-uWvEyQQWm0",
    "outputId": "28ecdf6e-2673-4f3f-fe3c-2f146e5d27c3"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Calculate base KNN model\n",
    "knn_mel_std = knn_base.fit(data_std['log mel'][0], data_std['log mel'][1])\n",
    "\n",
    "\n",
    "# Save model\n",
    "with open (model_dir + \"knn_mel_std\", \"wb\") as f:\n",
    "  pickle.dump(knn_mel_std, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results(data_std['log mel'][0], data_std['log mel'][1], data_std['log mel'][2], data_std['log mel'][3], knn_mel_std, 'ROC_knn_mel_std')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjwgpaWGs2eT"
   },
   "source": [
    "## KNN - Parameter Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrOYeGFtRLEP"
   },
   "source": [
    "### Powertransformed Spectogram Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DDoHdjNOs9Gi"
   },
   "outputs": [],
   "source": [
    "knn_params = {'n_neighbors':[1, 3, 5, 10, 50, 100]}\n",
    "knn_search = KNeighborsClassifier()\n",
    "knn_search = GridSearchCV(knn_search, knn_params, cv = 5,scoring = 'accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "Zt08ktKMtdw5",
    "outputId": "04d4a76b-f484-444f-bc5e-2d1431ded8da"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Fit model \n",
    "knn_mel_search = knn_search.fit(data_std['log mel'][0], data_std['log mel'][1])\n",
    "\n",
    "# Save model\n",
    "with open (model_dir + \"knn_mel_search\", \"wb\") as f:\n",
    "  pickle.dump(knn_mel_search, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "fdCkX4Dpvbuz",
    "outputId": "191ae33e-ffeb-425c-d9c6-79aca01626f7"
   },
   "outputs": [],
   "source": [
    "knn_mel_search_results = pd.DataFrame(knn_mel_search.cv_results_).sort_values(by=['rank_test_score'])\n",
    "knn_mel_search_results.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lb5ds7SLvhI8",
    "outputId": "2b37b247-cb3d-450d-cce1-e71eaea56075"
   },
   "outputs": [],
   "source": [
    "# Get the best parameters according to GridSearch\n",
    "print(knn_mel_search.best_params_)\n",
    "knn_mel_best_params = knn_mel_search.best_params_\n",
    "knn_mel_opt_ins = KNeighborsClassifier(n_neighbors = knn_mel_best_params['n_neighbors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "oTEbuOb1ZHvV",
    "outputId": "ab1e1e73-4bc7-4733-febb-49660fe593a6"
   },
   "outputs": [],
   "source": [
    "# Train Model\n",
    "\n",
    "knn_mel_opt = knn_mel_opt_ins.fit(data_std['log mel'][0], data_std['log mel'][1])\n",
    "\n",
    "# Save model\n",
    "with open (model_dir + \"knn_mel_opt\", \"wb\") as f:\n",
    "  pickle.dump(knn_mel_opt, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results(data_std['log mel'][0], data_std['log mel'][1], data_std['log mel'][2], data_std['log mel'][3], knn_mel_opt, 'ROC_knn_mel_opt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8lbjXoS8Or9"
   },
   "source": [
    "## Training a Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QapZulOa2Wtr"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CBPm18g52Y8S",
    "outputId": "198c29c4-906d-486b-f953-81cfe0a2db13"
   },
   "outputs": [],
   "source": [
    "# get one-hot encoded y matrix\n",
    "\n",
    "num_labels = np.unique(y_mel_train)\n",
    "y=np.array(num_labels.tolist())\n",
    "print(y)\n",
    "\n",
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))\n",
    "print(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WG_POI8d2bUI",
    "outputId": "80e5704d-8969-444f-8dee-38f3a60c6ef5"
   },
   "outputs": [],
   "source": [
    "y_mel_train_onehot = to_categorical(labelencoder.fit_transform(y_mel_train))\n",
    "y_mel_test_onehot = to_categorical(labelencoder.fit_transform(y_mel_test))\n",
    "\n",
    "print(y_mel_train_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gEIeBNU7l6SF",
    "outputId": "06cf948f-9f47-4b07-e806-bc823ac1eab6"
   },
   "outputs": [],
   "source": [
    "nn_input_shape = X_mel_train_flat.shape[1]\n",
    "print(nn_input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bE-2lBv92dLM",
    "outputId": "48b0a93b-8974-4709-ab3a-901ff95a92b7"
   },
   "outputs": [],
   "source": [
    "# BASIC NEURAL NETWORK\n",
    "model=Sequential()\n",
    "#1.\n",
    "model.add(Dense(200,input_shape=(nn_input_shape,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#2nd\n",
    "model.add(Dense(400))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#3rd\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#last layer\n",
    "model.add(Dense(y.shape[1]))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HwNnYS1U2fnk",
    "outputId": "e9ce5e64-5707-4199-e755-fc6776d3089b"
   },
   "outputs": [],
   "source": [
    "# Trianing the model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='/Users/brentonstefko/Desktop/Harvard/Practical/models/audio_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "snn_mel_base = model.fit(X_mel_train_flat, y_mel_train_onehot, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_mel_test_flat, y_mel_test_onehot), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "# Save model\n",
    "with open (\"snn_mel_base\", \"wb\") as f:\n",
    "  pickle.dump(snn_mel_base, f)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)\n",
    "\n",
    "# Calculate & Print Scores\n",
    "# snn_mel_train_score = snn_mel_base.evaluate(X_mel_train_flat ,y_mel_train_onehot,verbose=0)\n",
    "# print(snn_mel_train_score[1])\n",
    "# snn_mel_test_score =snn_mel_base.evaluate(X_mel_test_flat ,y_mel_test_onehot,verbose=0)\n",
    "# print(snn_mel_test_score[1])'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CFKgXnAa6tMk"
   },
   "outputs": [],
   "source": [
    "#Plot Model accuracy over training periods\n",
    "plt.plot(snn_mel_base.history['accuracy'])\n",
    "plt.plot(snn_mel_base.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ML2gCcKw74SB"
   },
   "outputs": [],
   "source": [
    "# Plot Model Loss over training periods\n",
    "plt.plot(snn_mel_base.history['loss'])\n",
    "plt.plot(snn_mel_base.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "* Train the model using the transformed mel spectogram data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Treat Mel Spectograms as Greyscale images\n",
    "print(X_mel_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X_train (must be 4-dimensional)\n",
    "train_images = X_mel_train.reshape(X_mel_train.shape[0], X_mel_train.shape[1], X_mel_train.shape[2], 1)\n",
    "test_images = X_mel_test.reshape(X_mel_test.shape[0], X_mel_test.shape[1], X_mel_test.shape[2], 1)\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize Mel Spectogram Data\n",
    "def mel_scaler(X_train, X_test):\n",
    "    mean = X_train.mean()\n",
    "    sd = X_test.std()\n",
    "    X_train = (X_train - mean)/sd\n",
    "    X_test = (X_test - mean)/sd\n",
    "    return(X_train, X_test)\n",
    "\n",
    "train_images_std, test_images_std = mel_scaler(train_images, test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional NEURAL NETWORK\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu', input_shape=(128, 87, 1)))\n",
    "cnn.add(MaxPooling2D(pool_size = (2, 2), strides = 2))\n",
    "cnn.add(Dropout(0.7))\n",
    "cnn.add(Conv2D(filters = 64, kernel_size = (3, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size = (2, 2), strides = 2))\n",
    "cnn.add(Dropout(0.7))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(1024, activation='relu'))\n",
    "cnn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "# cnn.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# cnn.add(MaxPooling2D(2, 2))\n",
    "# cnn.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# cnn.add(MaxPooling2D(2, 2))\n",
    "# cnn.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# cnn.add(MaxPooling2D(2, 2))\n",
    "# cnn.add(Flatten())\n",
    "# cnn.add(Dense(1024, activation='relu'))\n",
    "# cnn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "cnn.summary()\n",
    "\n",
    "cnn.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 10\n",
    "num_batch_size = 64\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='/Users/brentonstefko/Desktop/Harvard/Practical/models/cnn_audio_classification_2.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "cnn_mel_base = cnn.fit(train_images_std, y_mel_train_onehot, batch_size=num_batch_size, epochs=num_epochs, validation_data=(test_images_std, y_mel_test_onehot), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "# Save model\n",
    "with open (\"cnn_mel_base\", \"wb\") as f:\n",
    "  pickle.dump(cnn_mel_base, f)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Model accuracy over training periods\n",
    "plt.plot(cnn_mel_base.history['accuracy'])\n",
    "plt.plot(cnn_mel_base.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Model Loss over training periods\n",
    "plt.plot(cnn_mel_base.history['loss'])\n",
    "plt.plot(cnn_mel_base.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_gamma = Sequential()\n",
    "cnn_gamma.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 87, 1)))\n",
    "cnn_gamma.add(MaxPooling2D(2, 2))\n",
    "cnn_gamma.add(Dropout(0.05))\n",
    "cnn_gamma.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "cnn_gamma.add(MaxPooling2D(2, 2))\n",
    "cnn_gamma.add(Dropout(0.05))\n",
    "cnn_gamma.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "cnn_gamma.add(MaxPooling2D(2, 2))\n",
    "cnn_gamma.add(Dropout(0.05))\n",
    "cnn_gamma.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "cnn_gamma.add(MaxPooling2D(2, 2))\n",
    "cnn_gamma.add(Dropout(0.05))\n",
    "cnn_gamma.add(Flatten())\n",
    "cnn_gamma.add(Dense(1024, activation='relu'))\n",
    "cnn_gamma.add(Dense(10, activation='softmax'))\n",
    "cnn_gamma.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn_gamma.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 10\n",
    "num_batch_size = 64\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='/Users/brentonstefko/Desktop/Harvard/Practical/models/cnn_audio_classification_beta.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "cnn_gamma_mel_base = cnn_gamma.fit(train_images, y_mel_train_onehot, batch_size=num_batch_size, epochs=num_epochs, validation_data=(test_images, y_mel_test_onehot), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "# Save model\n",
    "with open (\"cnn_gamma_mel_base\", \"wb\") as f:\n",
    "  pickle.dump(cnn_gamma_mel_base, f)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Model accuracy over training periods\n",
    "plt.plot(cnn_gamma_mel_base.history['accuracy'])\n",
    "plt.plot(cnn_gamma_mel_base.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "9M6m9erVnS7V",
    "cEougCmMplmy",
    "zeTQFmR3O9Q_",
    "q8lbjXoS8Or9"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
